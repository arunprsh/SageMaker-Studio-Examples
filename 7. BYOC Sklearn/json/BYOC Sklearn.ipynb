{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Scikit-Learn Model using SageMaker\n",
    "#### Bring Your Own Container (BYOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Train Script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train\n"
     ]
    }
   ],
   "source": [
    "%%file train\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Define paths for Model Training inside Container.\n",
    "INPUT_PATH = '/opt/ml/input/data'\n",
    "OUTPUT_PATH = '/opt/ml/output'\n",
    "MODEL_PATH = '/opt/ml/model'\n",
    "PARAM_PATH = '/opt/ml/input/config/hyperparameters.json'\n",
    "\n",
    "# Training data sitting in S3 will be copied to this location during training when used with File MODE.\n",
    "TRAIN_DATA_PATH = f'{INPUT_PATH}/train'\n",
    "TEST_DATA_PATH = f'{INPUT_PATH}/test'\n",
    "\n",
    "def train():\n",
    "    print(\"------- [STARTING TRAINING] -------\")\n",
    "    train_df = pd.read_csv(os.path.join(TRAIN_DATA_PATH, 'train.csv'), names=['class', 'bmi', 'diastolic_bp_change', 'systolic_bp_change', 'respiratory_rate'])\n",
    "    train_df.head()\n",
    "    X_train = train_df[['bmi', 'diastolic_bp_change', 'systolic_bp_change', 'respiratory_rate']]\n",
    "    y_train = train_df['class']\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Save the trained Model inside the Container\n",
    "    with open(os.path.join(MODEL_PATH, 'model.pkl'), 'wb') as out:\n",
    "        pickle.dump(knn, out)\n",
    "    print(\"------- [TRAINING COMPLETE!] -------\")\n",
    "    \n",
    "    print(\"------- [STARTING EVALUATION] -------\")\n",
    "    test_df = pd.read_csv(os.path.join(TEST_DATA_PATH, 'test.csv'), names=['class', 'bmi', 'diastolic_bp_change', 'systolic_bp_change', 'respiratory_rate'])\n",
    "    X_test = train_df[['bmi', 'diastolic_bp_change', 'systolic_bp_change', 'respiratory_rate']]\n",
    "    y_test = train_df['class']\n",
    "    acc = knn.score(X_test, y_test)\n",
    "    print('Accuracy = {:.2f}%'.format(acc * 100))\n",
    "    print(\"------- [EVALUATION DONE!] -------\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Serve Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting serve\n"
     ]
    }
   ],
   "source": [
    "%%file serve\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from flask import Flask, Response, request\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "MODEL_PATH = '/opt/ml/model'\n",
    "\n",
    "# Singleton Class for holding the Model\n",
    "class Predictor:\n",
    "    model = None\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls):\n",
    "        print('[LOADING MODEL]')\n",
    "        if cls.model is None:\n",
    "            with open(os.path.join(MODEL_PATH, 'model.pkl'), 'rb') as file_:\n",
    "                cls.model = pickle.load(file_)\n",
    "        print('MODEL LOADED!')\n",
    "        return cls.model\n",
    "    \n",
    "    @classmethod\n",
    "    def predict(cls, X):\n",
    "        X = X.reshape(1, -1)\n",
    "        clf = cls.load_model()\n",
    "        return clf.predict(X)\n",
    "\n",
    "@app.route('/ping', methods=['GET'])\n",
    "def ping():\n",
    "    print('[HEALTH CHECK]')\n",
    "    model = Predictor.load_model()\n",
    "    status = 200\n",
    "    if model is None:\n",
    "        status = 404\n",
    "    return Response(response={\"HEALTH CHECK\": \"OK\"}, status=status, mimetype='application/json')\n",
    "\n",
    "@app.route('/invocations', methods=['POST'])\n",
    "def invoke():\n",
    "    data = None\n",
    "    if request.content_type == 'application/json':\n",
    "        data = request.data\n",
    "        data = json.loads(data.decode('utf8'))\n",
    "        features = data['instances']\n",
    "        features = np.array(features)\n",
    "    else:\n",
    "        return Response(response='This Predictor only supports JSON data', status=415, mimetype='text/plain')\n",
    "\n",
    "    prediction = Predictor.predict(features)    \n",
    "    result = {'predictions': prediction.tolist()}\n",
    "    result = json.dumps(result, indent=2).encode('utf-8')\n",
    "    return Response(response=result, status=200, mimetype='application/json')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a Docker Image and Push to ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Build the docker image and push to ECR and have the image URI handy for the next steps.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  115.2kB\n",
      "Step 1/8 : FROM python:3.7\n",
      "3.7: Pulling from library/python\n",
      "\n",
      "\u001b[1Bc589d5f9: Pulling fs layer \n",
      "\u001b[1Be46d8b5f: Pulling fs layer \n",
      "\u001b[1B8ad42f0d: Pulling fs layer \n",
      "\u001b[1B137f8d26: Pulling fs layer \n",
      "\u001b[1Bf6ed9b0c: Pulling fs layer \n",
      "\u001b[1B279f50e0: Pulling fs layer \n",
      "\u001b[1B8cd4d4c8: Pulling fs layer \n",
      "\u001b[1B0f545211: Pulling fs layer \n",
      "\u001b[1BDigest: sha256:0a2f2121ff7d017e873992ca23ab8516786913cc3cde8270a88051ab6379dd06[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
      "Status: Downloaded newer image for python:3.7\n",
      " ---> 9f71717f61f8\n",
      "Step 2/8 : COPY requirements.txt ./\n",
      " ---> 560a2a50622b\n",
      "Step 3/8 : RUN pip install --no-cache-dir -r requirements.txt\n",
      " ---> Running in e66115e3baf7\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "Collecting flask\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
      "Collecting numpy>=1.16.5\n",
      "  Downloading numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "Installing collected packages: six, numpy, MarkupSafe, Werkzeug, threadpoolctl, scipy, pytz, python-dateutil, joblib, Jinja2, itsdangerous, click, scikit-learn, pandas, flask\n",
      "Successfully installed Jinja2-2.11.3 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 flask-1.1.2 itsdangerous-1.1.0 joblib-1.0.1 numpy-1.20.2 pandas-1.2.3 python-dateutil-2.8.1 pytz-2021.1 scikit-learn-0.24.1 scipy-1.6.2 six-1.15.0 threadpoolctl-2.1.0\n",
      "Removing intermediate container e66115e3baf7\n",
      " ---> a36185fa0c93\n",
      "Step 4/8 : COPY train /usr/local/bin\n",
      " ---> 153af7111d44\n",
      "Step 5/8 : RUN chmod +x /usr/local/bin/train\n",
      " ---> Running in 9866ff178d24\n",
      "Removing intermediate container 9866ff178d24\n",
      " ---> 2949b33d95b4\n",
      "Step 6/8 : COPY serve /usr/local/bin\n",
      " ---> 362d2899f97a\n",
      "Step 7/8 : RUN chmod +x /usr/local/bin/serve\n",
      " ---> Running in bebefeba6f91\n",
      "Removing intermediate container bebefeba6f91\n",
      " ---> fec62e458ccb\n",
      "Step 8/8 : EXPOSE 8080\n",
      " ---> Running in 6523563f1dea\n",
      "Removing intermediate container 6523563f1dea\n",
      " ---> 6cee32a5d021\n",
      "Successfully built 6cee32a5d021\n",
      "Successfully tagged sagemaker-byoc-sklearn:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t sagemaker-byoc-sklearn -f Dockerfile ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time BEFORE we rebuild the docker image making changes to the training or the inference scripts, run the below commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker stop $(docker ps -a -q)`<br>\n",
    "`docker rm $(docker ps -a -q)`<br>\n",
    "`docker image prune -a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to stop all running docker processes and reflush images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push local Docker image to ECR (can be SKIPPED since running in Local Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container Name:  sagemaker-byoc-sklearn\n",
      "Account:  892313895307\n",
      "Region: us-east-1\n",
      "ECR Repository:  892313895307.dkr.ecr.us-east-1.amazonaws.com\n",
      "ECR Image URI:  892313895307.dkr.ecr.us-east-1.amazonaws.com/sagemaker-byoc-sklearn:latest\n",
      "Login Succeeded\n",
      "The push refers to repository [892313895307.dkr.ecr.us-east-1.amazonaws.com/sagemaker-byoc-sklearn]\n",
      "638ad6f92a0f: Preparing\n",
      "51c52955af91: Preparing\n",
      "6ce7ccc1396d: Preparing\n",
      "f9cdc0b28671: Preparing\n",
      "90e90bb010df: Preparing\n",
      "f078a683635a: Preparing\n",
      "78e4e1f4c63c: Preparing\n",
      "1aec1a899afd: Preparing\n",
      "0cd56214ad4c: Preparing\n",
      "5c4d1446babf: Preparing\n",
      "a777ce0e8966: Preparing\n",
      "da2a03e6ee94: Preparing\n",
      "3e29ce682bef: Preparing\n",
      "a576cb5bb7d1: Preparing\n",
      "c1bcddf0e470: Preparing\n",
      "78e4e1f4c63c: Waiting\n",
      "1aec1a899afd: Waiting\n",
      "0cd56214ad4c: Waiting\n",
      "5c4d1446babf: Waiting\n",
      "a777ce0e8966: Waiting\n",
      "da2a03e6ee94: Waiting\n",
      "3e29ce682bef: Waiting\n",
      "a576cb5bb7d1: Waiting\n",
      "c1bcddf0e470: Waiting\n",
      "f078a683635a: Waiting\n",
      "f9cdc0b28671: Pushed\n",
      "6ce7ccc1396d: Pushed\n",
      "638ad6f92a0f: Pushed\n",
      "51c52955af91: Pushed\n",
      "f078a683635a: Layer already exists\n",
      "78e4e1f4c63c: Layer already exists\n",
      "1aec1a899afd: Layer already exists\n",
      "0cd56214ad4c: Layer already exists\n",
      "5c4d1446babf: Layer already exists\n",
      "a777ce0e8966: Layer already exists\n",
      "da2a03e6ee94: Layer already exists\n",
      "a576cb5bb7d1: Layer already exists\n",
      "c1bcddf0e470: Layer already exists\n",
      "3e29ce682bef: Layer already exists\n",
      "90e90bb010df: Pushed\n",
      "latest: digest: sha256:689b154c994f54630dcaf60b48f45fb361468410f1fbccda6d2edfc5a69aa704 size: 3465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify a name to your custom container\n",
    "container_name=sagemaker-byoc-sklearn\n",
    "echo \"Container Name: \" ${container_name}\n",
    "\n",
    "# Retreive AWS account ID\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the AWS region defined in the current configuration (default to us-east-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "echo \"Account: \" ${account}\n",
    "echo \"Region: \"${region}\n",
    "\n",
    "repository=\"${account}.dkr.ecr.${region}.amazonaws.com\"\n",
    "echo \"ECR Repository: \" ${repository}\n",
    "\n",
    "image=\"${account}.dkr.ecr.${region}.amazonaws.com/${container_name}:latest\"\n",
    "echo \"ECR Image URI: \" ${image}\n",
    "\n",
    "# If the ECR repository does not exist, create it.\n",
    "aws ecr describe-repositories --repository-names ${container_name} > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name ${container_name} > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${repository}\n",
    "\n",
    "# Tag the local image with ECR image name\n",
    "docker tag ${container_name} ${image}\n",
    "\n",
    "# Finally, push the local docker image to ECR with the full ECR image name\n",
    "docker push ${image}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train your Custom Sklearn Model using SageMaker Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from time import gmtime, strftime\n",
    "import pandas as pd\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "account = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = session.boto_session.region_name\n",
    "image_name = 'sagemaker-byoc-sklearn'\n",
    "image_uri = f'{account}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest'  # local copy to be pushed to ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train (using SageMaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = '../.././DATA'\n",
    "\n",
    "train_data_s3_pointer = session.upload_data(f'{WORK_DIRECTORY}/train', key_prefix='byoc-sklearn/train')\n",
    "test_data_s3_pointer = session.upload_data(f'{WORK_DIRECTORY}/test', key_prefix='byoc-sklearn/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    sagemaker_session=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-28 21:02:40 Starting - Starting the training job...\n",
      "2021-03-28 21:03:06 Starting - Launching requested ML instancesProfilerReport-1616965360: InProgress\n",
      ".........\n",
      "2021-03-28 21:04:26 Starting - Preparing the instances for training...\n",
      "2021-03-28 21:05:08 Downloading - Downloading input data\n",
      "2021-03-28 21:05:08 Training - Downloading the training image.....\u001b[34m------- [STARTING TRAINING] -------\u001b[0m\n",
      "\u001b[34m------- [TRAINING COMPLETE!] -------\u001b[0m\n",
      "\u001b[34m------- [STARTING EVALUATION] -------\u001b[0m\n",
      "\u001b[34mAccuracy = 82.42%\u001b[0m\n",
      "\u001b[34m------- [EVALUATION DONE!] -------\u001b[0m\n",
      "\n",
      "2021-03-28 21:06:06 Uploading - Uploading generated training model\n",
      "2021-03-28 21:06:06 Completed - Training job completed\n",
      "Training seconds: 68\n",
      "Billable seconds: 68\n"
     ]
    }
   ],
   "source": [
    "model.fit({'train': train_data_s3_pointer, 'test': test_data_s3_pointer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Trained Model as SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "current_timestamp = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "json_serializer = JSONSerializer()\n",
    "json_deserializer = JSONDeserializer()\n",
    "predictor = model.deploy(1, \n",
    "                         'ml.m5.xlarge', \n",
    "                         endpoint_name=f'emr-byoc-sklearn-{current_timestamp}', \n",
    "                         serializer=json_serializer,\n",
    "                         deserializer=json_deserializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Time Inference using Deployed Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../.././DATA/test/test.csv', header=None)\n",
    "test_df = df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.179054</td>\n",
       "      <td>0.228029</td>\n",
       "      <td>-0.431359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4\n",
       "2241  0.022906  0.179054  0.228029 -0.431359"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.drop(test_df.columns[[0]], axis=1, inplace=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02290556,  0.17905413,  0.22802851, -0.43135912]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = test_df.values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = list(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02290556213751108,\n",
       " 0.1790541330317105,\n",
       " 0.22802851099356705,\n",
       " -0.431359120978368]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': [[0.02290556213751108,\n",
       "   0.1790541330317105,\n",
       "   0.22802851099356705,\n",
       "   -0.431359120978368]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {'instances': [x_]}\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [0]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
