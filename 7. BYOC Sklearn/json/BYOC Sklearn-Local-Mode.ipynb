{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Scikit-Learn Model using SageMaker (Local Mode)\n",
    "#### Bring Your Own Container (BYOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Train Script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train\n"
     ]
    }
   ],
   "source": [
    "%%file train\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Define paths for Model Training inside Container.\n",
    "INPUT_PATH = '/opt/ml/input/data'\n",
    "OUTPUT_PATH = '/opt/ml/output'\n",
    "MODEL_PATH = '/opt/ml/model'\n",
    "PARAM_PATH = '/opt/ml/input/config/hyperparameters.json'\n",
    "\n",
    "# Training data sitting in S3 will be copied to this location during training when used with File MODE.\n",
    "TRAIN_DATA_PATH = f'{INPUT_PATH}/train'\n",
    "TEST_DATA_PATH = f'{INPUT_PATH}/test'\n",
    "\n",
    "def train():\n",
    "    print(\"------- [STARTING TRAINING] -------\")\n",
    "    train_df = pd.read_csv(os.path.join(TRAIN_DATA_PATH, 'train.csv'), names=['class', 'bmi', 'diastolic_bp_change', 'systolic_bp_change', 'respiratory_rate'])\n",
    "    train_df.head()\n",
    "    X_train = train_df[['bmi', 'diastolic_bp_change', 'systolic_bp_change', 'respiratory_rate']]\n",
    "    y_train = train_df['class']\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Save the trained Model inside the Container\n",
    "    with open(os.path.join(MODEL_PATH, 'model.pkl'), 'wb') as out:\n",
    "        pickle.dump(knn, out)\n",
    "    print(\"------- [TRAINING COMPLETE!] -------\")\n",
    "    \n",
    "    print(\"------- [STARTING EVALUATION] -------\")\n",
    "    test_df = pd.read_csv(os.path.join(TEST_DATA_PATH, 'test.csv'), names=['class', 'bmi', 'diastolic_bp_change', 'systolic_bp_change', 'respiratory_rate'])\n",
    "    X_test = train_df[['bmi', 'diastolic_bp_change', 'systolic_bp_change', 'respiratory_rate']]\n",
    "    y_test = train_df['class']\n",
    "    acc = knn.score(X_test, y_test)\n",
    "    print('Accuracy = {:.2f}%'.format(acc * 100))\n",
    "    print(\"------- [EVALUATION DONE!] -------\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Serve Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting serve\n"
     ]
    }
   ],
   "source": [
    "%%file serve\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from flask import Flask, Response, request\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "MODEL_PATH = '/opt/ml/model'\n",
    "\n",
    "# Singleton Class for holding the Model\n",
    "class Predictor:\n",
    "    model = None\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls):\n",
    "        print('[LOADING MODEL]')\n",
    "        if cls.model is None:\n",
    "            with open(os.path.join(MODEL_PATH, 'model.pkl'), 'rb') as file_:\n",
    "                cls.model = pickle.load(file_)\n",
    "        print('MODEL LOADED!')\n",
    "        return cls.model\n",
    "    \n",
    "    @classmethod\n",
    "    def predict(cls, X):\n",
    "        X = X.reshape(1, -1)\n",
    "        print(f'X: {X}')\n",
    "        clf = cls.load_model()\n",
    "        return clf.predict(X)\n",
    "\n",
    "@app.route('/ping', methods=['GET'])\n",
    "def ping():\n",
    "    print('[HEALTH CHECK]')\n",
    "    model = Predictor.load_model()\n",
    "    status = 200\n",
    "    if model is None:\n",
    "        status = 404\n",
    "    return Response(response={\"HEALTH CHECK\": \"OK\"}, status=status, mimetype='application/json')\n",
    "\n",
    "@app.route('/invocations', methods=['POST'])\n",
    "def invoke():\n",
    "    data = None\n",
    "    if request.content_type == 'application/json':\n",
    "        data = request.data\n",
    "        data = json.loads(data.decode('utf8'))\n",
    "        features = data['instances']\n",
    "        features = np.array(features)\n",
    "    else:\n",
    "        return Response(response='This Predictor only supports JSON data', status=415, mimetype='text/plain')\n",
    "\n",
    "    prediction = Predictor.predict(features)\n",
    "    print('prediction', prediction)\n",
    "    \n",
    "    result = {'predictions': prediction.tolist()}\n",
    "    result = json.dumps(result, indent=2).encode('utf-8')\n",
    "    return Response(response=result, status=200, mimetype='application/json')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a Docker Image and Push to ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Build the docker image and push to ECR and have the image URI handy for the next steps.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  134.7kB\n",
      "Step 1/8 : FROM python:3.7\n",
      "3.7: Pulling from library/python\n",
      "\n",
      "\u001b[1Bc589d5f9: Pulling fs layer \n",
      "\u001b[1Be46d8b5f: Pulling fs layer \n",
      "\u001b[1B8ad42f0d: Pulling fs layer \n",
      "\u001b[1B137f8d26: Pulling fs layer \n",
      "\u001b[1Bf6ed9b0c: Pulling fs layer \n",
      "\u001b[1B279f50e0: Pulling fs layer \n",
      "\u001b[1B8cd4d4c8: Pulling fs layer \n",
      "\u001b[1B0f545211: Pulling fs layer \n",
      "\u001b[1B69c80101: Pull complete 165MB/2.165MBB\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:0a2f2121ff7d017e873992ca23ab8516786913cc3cde8270a88051ab6379dd06\n",
      "Status: Downloaded newer image for python:3.7\n",
      " ---> 9f71717f61f8\n",
      "Step 2/8 : COPY requirements.txt ./\n",
      " ---> 7f1e0161dbfd\n",
      "Step 3/8 : RUN pip install --no-cache-dir -r requirements.txt\n",
      " ---> Running in ee772a187142\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "Collecting flask\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting numpy>=1.16.5\n",
      "  Downloading numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "Installing collected packages: six, numpy, MarkupSafe, Werkzeug, threadpoolctl, scipy, pytz, python-dateutil, joblib, Jinja2, itsdangerous, click, scikit-learn, pandas, flask\n",
      "Successfully installed Jinja2-2.11.3 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 flask-1.1.2 itsdangerous-1.1.0 joblib-1.0.1 numpy-1.20.2 pandas-1.2.3 python-dateutil-2.8.1 pytz-2021.1 scikit-learn-0.24.1 scipy-1.6.2 six-1.15.0 threadpoolctl-2.1.0\n",
      "Removing intermediate container ee772a187142\n",
      " ---> 83ab236acd22\n",
      "Step 4/8 : COPY train /usr/local/bin\n",
      " ---> 165d69fbaab8\n",
      "Step 5/8 : RUN chmod +x /usr/local/bin/train\n",
      " ---> Running in 53beb01f54da\n",
      "Removing intermediate container 53beb01f54da\n",
      " ---> d9cd520b4cc1\n",
      "Step 6/8 : COPY serve /usr/local/bin\n",
      " ---> d8f8456a810e\n",
      "Step 7/8 : RUN chmod +x /usr/local/bin/serve\n",
      " ---> Running in 9c606241c5c2\n",
      "Removing intermediate container 9c606241c5c2\n",
      " ---> 4da599d2d15d\n",
      "Step 8/8 : EXPOSE 8080\n",
      " ---> Running in 44353bd597be\n",
      "Removing intermediate container 44353bd597be\n",
      " ---> 05a9d52606d6\n",
      "Successfully built 05a9d52606d6\n",
      "Successfully tagged sagemaker-byoc-sklearn:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t sagemaker-byoc-sklearn -f Dockerfile ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time BEFORE we rebuild the docker image making changes to the training or the inference scripts, run the below commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker stop $(docker ps -a -q)`<br>\n",
    "`docker rm $(docker ps -a -q)`<br>\n",
    "`docker image prune -a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to stop all running docker processes and reflush images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push local Docker image to ECR (can be SKIPPED since running in Local Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify a name to your custom container\n",
    "container_name=sagemaker-byoc-sklearn\n",
    "echo \"Container Name: \" ${container_name}\n",
    "\n",
    "# Retreive AWS account ID\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the AWS region defined in the current configuration (default to us-east-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "echo \"Account: \" ${account}\n",
    "echo \"Region: \"${region}\n",
    "\n",
    "repository=\"${account}.dkr.ecr.${region}.amazonaws.com\"\n",
    "echo \"ECR Repository: \" ${repository}\n",
    "\n",
    "image=\"${account}.dkr.ecr.${region}.amazonaws.com/${container_name}:latest\"\n",
    "echo \"ECR Image URI: \" ${image}\n",
    "\n",
    "# If the ECR repository does not exist, create it.\n",
    "aws ecr describe-repositories --repository-names ${container_name} > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name ${container_name} > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${repository}\n",
    "\n",
    "# Tag the local image with ECR image name\n",
    "docker tag ${container_name} ${image}\n",
    "\n",
    "# Finally, push the local docker image to ECR with the full ECR image name\n",
    "docker push ${image}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train your Custom Sklearn Model using SageMaker Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "import pandas as pd\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "account = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = session.boto_session.region_name\n",
    "image_name = 'sagemaker-byoc-sklearn'\n",
    "#image_uri = f'{account}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest'  # local copy to be pushed to ECR\n",
    "image_uri = f'{image_name}:latest' # refer to the local docker image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train (Local Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    sagemaker_session=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 2gh92nlho5-algo-1-vhzza ... \n",
      "Creating 2gh92nlho5-algo-1-vhzza ... done\n",
      "Attaching to 2gh92nlho5-algo-1-vhzza\n",
      "\u001b[36m2gh92nlho5-algo-1-vhzza |\u001b[0m ------- [STARTING TRAINING] -------\n",
      "\u001b[36m2gh92nlho5-algo-1-vhzza |\u001b[0m ------- [TRAINING COMPLETE!] -------\n",
      "\u001b[36m2gh92nlho5-algo-1-vhzza |\u001b[0m ------- [STARTING EVALUATION] -------\n",
      "\u001b[36m2gh92nlho5-algo-1-vhzza |\u001b[0m Accuracy = 82.42%\n",
      "\u001b[36m2gh92nlho5-algo-1-vhzza |\u001b[0m ------- [EVALUATION DONE!] -------\n",
      "\u001b[36m2gh92nlho5-algo-1-vhzza exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "model.fit({'train': 'file://../.././DATA/train/train.csv', 'test': 'file://../.././DATA/test/test.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Trained Model as SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to ham81dqy28-algo-1-t81d8\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m  * Serving Flask app \"serve\" (lazy loading)\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m  * Environment: production\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m \u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m \u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m  * Debug mode: off\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m  * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m [HEALTH CHECK]\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m [LOADING MODEL]\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m MODEL LOADED!\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m 172.18.0.1 - - [28/Mar/2021 16:36:21] \"\u001b[37mGET /ping HTTP/1.1\u001b[0m\" 200 -\n",
      "!"
     ]
    }
   ],
   "source": [
    "json_serializer = JSONSerializer()\n",
    "json_deserializer = JSONDeserializer()\n",
    "predictor = model.deploy(1, \n",
    "                         'local', \n",
    "                         endpoint_name='emr-byoc-sklearn', \n",
    "                         serializer=json_serializer,\n",
    "                         deserializer=json_deserializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Time Inference using Deployed Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../.././DATA/test/test.csv', header=None)\n",
    "test_df = df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>-1.161747</td>\n",
       "      <td>-0.758273</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.481227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4\n",
       "1586 -1.161747 -0.758273  0.394461  0.481227"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.drop(test_df.columns[[0]], axis=1, inplace=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.16174745, -0.75827256,  0.3944615 ,  0.48122704]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = test_df.values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = list(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.1617474484872234,\n",
       " -0.7582725561441886,\n",
       " 0.3944614964772361,\n",
       " 0.4812270430077439]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': [[-1.1617474484872234,\n",
       "   -0.7582725561441886,\n",
       "   0.3944614964772361,\n",
       "   0.4812270430077439]]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {'instances': [x_]}\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m X: [[-1.16174745 -0.75827256  0.3944615   0.48122704]]\r\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m [LOADING MODEL]\r\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m MODEL LOADED!\r\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m prediction [0]\r\n",
      "\u001b[36mham81dqy28-algo-1-t81d8 |\u001b[0m 172.18.0.1 - - [28/Mar/2021 16:36:24] \"\u001b[37mPOST /invocations HTTP/1.1\u001b[0m\" 200 -\r\n"
     ]
    }
   ],
   "source": [
    "prediction = predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [0]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
